{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77a3b40",
   "metadata": {},
   "source": [
    "# 03 â€” Insights & Sanity Checks\n",
    "\n",
    "- How much data was missing and got imputed?\n",
    "- Did imputation materially change distributions/seasonality?\n",
    "- Simple predictive sanity: do lagged usages correlate with current usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaee980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "csv_path = \"../data/data_test.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "miss_rate = df['lusage'].isna().mean()\n",
    "n = len(df)\n",
    "print(f\"Missing lusage: {miss_rate:.1%} ({df['lusage'].isna().sum()} of {n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50318ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you've run one of the imputation notebooks or scripts and saved output to CSV,\n",
    "# load it here and compare. For demo, reuse baseline calculation quickly:\n",
    "dfb = df.copy()\n",
    "med1 = dfb.groupby(['year','month','mozip'])['lusage'].median()\n",
    "med2 = dfb.groupby(['zipcode','month'])['lusage'].median()\n",
    "global_med = dfb['lusage'].median()\n",
    "def fill_row(r):\n",
    "    if pd.notnull(r['lusage']): return r['lusage']\n",
    "    v = med1.get((r['year'],r['month'],r['mozip']), np.nan)\n",
    "    if pd.isna(v): v = med2.get((r['zipcode'],r['month']), np.nan)\n",
    "    if pd.isna(v): v = global_med\n",
    "    return v\n",
    "dfb['lusage_imp'] = dfb.apply(fill_row, axis=1)\n",
    "\n",
    "pre_avg = df['lusage'].mean()\n",
    "post_avg = dfb['lusage_imp'].mean()\n",
    "print(\"Pre avg:\", pre_avg, \"Post avg (baseline):\", post_avg)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
